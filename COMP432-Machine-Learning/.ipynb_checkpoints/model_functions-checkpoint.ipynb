{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation of the Combined Linear SVM Weight and ReliefF algorithms for Dimensionality Reduction\n",
    "## From scratch, by Marc Vicuna and Dan Raileanu\n",
    "### References to the theory of this implementation at the end of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial as sp #for KDTree\n",
    "import sklearn.svm\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "# Variable of the RFE Linear SVM Weight Feature Selection. \n",
    "# If the training of the SVM is too slow, you may modify this constant to\n",
    "RFE_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "def prep_data(filename):\n",
    "    data = np.loadtxt('toy_dataset.csv',delimiter=\",\")\n",
    "    X, Y = data[:,:-1], data[:,-1].astype('i4')\n",
    "    X = sklearn.preprocessing.StandardScaler().fit_transform(X)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighs the ReliefF, ReliefF model definition, assumes the KDTree sorting has already been done\n",
    "def ReliefF(X, Y, m, k):\n",
    "    #initialization\n",
    "    W = np.zeros(X.shape[1])\n",
    "    trees = np.array([sp.KDTree(X[Y==i]) for i in range(len(np.unique(Y)))]) #O(cnlogn)\n",
    "    #choosing random points\n",
    "    choice = np.random.choice(np.arange(len(X)),m)\n",
    "    #maximums and minimums of all features\n",
    "    maximums, minimums = np.max(X, axis=0), np.min(X, axis=0)\n",
    "    P = np.unique(Y, return_counts = True)[1]/len(Y)\n",
    "    for i in range(m): #for each point\n",
    "        #point definition\n",
    "        x, y = X[choice[i]], Y[choice[i]]\n",
    "        current = trees[y]\n",
    "        hits = np.array(current.query(x, k=k+1)[1], dtype='i4')\n",
    "        misses = np.array([tree.query(x, k=k)[1] if tree != current else np.zeros(k) for tree in trees], dtype='i4')\n",
    "        for j in range(X.shape[1]):\n",
    "            W[j] += -np.sum(diff(x[j], X[hits].T[j], maximums[j], minimums[j]))/(m*k)\n",
    "            W[j] += np.sum(np.array([P[category]/(1-P[y])*sum(diff(x[j], X[misses[category]].T[j], maximums[j], minimums[j])) for category in range(len(P)) if category != y]))/(k*m)\n",
    "    return W\n",
    "# auxiliary function to ReliefF, true to the theory of ReliefF\n",
    "def diff(p1,p2,maxi,mini):\n",
    "    return np.absolute(p1-p2)/(maxi-mini)\n",
    "\n",
    "# Weighs the linear SVM weight model\n",
    "def linearSVM(X,Y): #assumes SVM random search for parameters tol and C\n",
    "    if len(X) > X.shape[1]:\n",
    "        svm = sklearn.svm.LinearSVC(dual=False, max_iter=1000)\n",
    "    else:\n",
    "        svm = sklearn.svm.LinearSVC(max_iter=1000)\n",
    "    param_dist = {'C': np.logspace(-3, 2, 6)}\n",
    "    r_search = sklearn.model_selection.RandomizedSearchCV(svm, param_distributions={'C': np.logspace(-3, 2, 6)}, n_iter=10, cv = 3, random_state=0)\n",
    "    r_search.fit(X,Y)\n",
    "    weights = r_search.best_estimator_.coef_\n",
    "    if (len(weights)==1):\n",
    "        return weights[0]\n",
    "    else:\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] = np.argsort(np.abs(weights[i]))\n",
    "        return np.sum(weights, axis=0)\n",
    "\n",
    "# Reduces the dimension of X based on the sorting of the weight \n",
    "# (the weights with greatest magnitude are the most important features)\n",
    "def reduce_X(X, W, remove):\n",
    "    return X[:,np.argsort(np.abs(W))[remove:]]\n",
    "\n",
    "# ReliefF Feature Selection Model\n",
    "def ReliefFSelect(X, Y, m, k, remove):\n",
    "    return reduce_X(X, ReliefF(X, Y, m, k), remove)\n",
    "\n",
    "# Linear SVM Weight Feature Selection Model\n",
    "def linearSVMWeightSelect(X,Y, remove):\n",
    "    return reduce_X(X, linearSVM(X,Y), remove)\n",
    "\n",
    "# main model, combination of 2 models\n",
    "# multilayered feature selection\n",
    "def combinedReliefFLinearSVM(X, Y, m, k, part, total):\n",
    "    # first layer\n",
    "    #RFE Linear SVM Weight Feature Selection\n",
    "    RFE_step = 1\n",
    "    i=0\n",
    "    while RFE_step*i < part:\n",
    "        X = linearSVMWeightSelect(X,Y, RFE_step)\n",
    "        i += 1\n",
    "    # second layer\n",
    "    return ReliefFSelect(X, Y, m, k, total-i*RFE_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the preprocessed data\n",
      "[[-0.68097166  0.4125685  -1.86760716 -1.61644772  1.59099026 -1.67125804]\n",
      " [-0.16213611  0.825137   -1.86760716 -1.61644772  1.23743687  1.67125804]\n",
      " [ 0.87553499 -0.825137    0.80836728  0.1796053  -0.1767767  -1.67125804]\n",
      " [-1.71864275 -1.65027399  0.36237154 -0.1796053  -1.23743687  0.92847669]\n",
      " [-1.71864275 -1.2377055  -0.52961994 -1.61644772 -0.53033009  1.29986737]\n",
      " [-0.16213611  1.2377055   0.36237154  0.89802651  1.59099026 -0.18569534]\n",
      " [-0.68097166  0.          1.70035875  0.53881591 -0.88388348 -0.55708601]\n",
      " [ 0.87553499 -1.2377055  -0.52961994 -0.1796053  -1.59099026  0.92847669]\n",
      " [ 0.87553499 -0.825137   -0.0836242   0.89802651 -0.1767767  -0.92847669]\n",
      " [ 0.35669944  0.825137   -0.0836242   1.25723711  0.88388348  0.55708601]\n",
      " [ 0.35669944  0.825137    1.70035875  1.61644772  0.88388348  0.18569534]\n",
      " [ 0.35669944  1.65027399  0.36237154 -0.53881591 -0.88388348  0.92847669]\n",
      " [ 2.43204163  0.825137   -0.0836242   0.1796053   0.88388348 -0.55708601]\n",
      " [-0.16213611  0.4125685   0.80836728  0.89802651 -0.88388348 -0.55708601]\n",
      " [-0.68097166  0.         -0.97561568  0.1796053  -0.53033009 -0.92847669]\n",
      " [-0.16213611 -1.2377055  -0.0836242  -0.89802651 -0.1767767   0.55708601]]\n",
      "This is the data chosen by the ReliefF\n",
      "[[-1.61644772  0.4125685 ]\n",
      " [-1.61644772  0.825137  ]\n",
      " [ 0.1796053  -0.825137  ]\n",
      " [-0.1796053  -1.65027399]\n",
      " [-1.61644772 -1.2377055 ]\n",
      " [ 0.89802651  1.2377055 ]\n",
      " [ 0.53881591  0.        ]\n",
      " [-0.1796053  -1.2377055 ]\n",
      " [ 0.89802651 -0.825137  ]\n",
      " [ 1.25723711  0.825137  ]\n",
      " [ 1.61644772  0.825137  ]\n",
      " [-0.53881591  1.65027399]\n",
      " [ 0.1796053   0.825137  ]\n",
      " [ 0.89802651  0.4125685 ]\n",
      " [ 0.1796053   0.        ]\n",
      " [-0.89802651 -1.2377055 ]]\n",
      "This is the data chosen by the Linear SVM weights\n",
      "[[-1.61644772  0.4125685 ]\n",
      " [-1.61644772  0.825137  ]\n",
      " [ 0.1796053  -0.825137  ]\n",
      " [-0.1796053  -1.65027399]\n",
      " [-1.61644772 -1.2377055 ]\n",
      " [ 0.89802651  1.2377055 ]\n",
      " [ 0.53881591  0.        ]\n",
      " [-0.1796053  -1.2377055 ]\n",
      " [ 0.89802651 -0.825137  ]\n",
      " [ 1.25723711  0.825137  ]\n",
      " [ 1.61644772  0.825137  ]\n",
      " [-0.53881591  1.65027399]\n",
      " [ 0.1796053   0.825137  ]\n",
      " [ 0.89802651  0.4125685 ]\n",
      " [ 0.1796053   0.        ]\n",
      " [-0.89802651 -1.2377055 ]]\n",
      "This is the data chosen by the combined ReliefF and Linear SVM weights\n",
      "[[-1.86760716 -1.61644772]\n",
      " [-1.86760716 -1.61644772]\n",
      " [ 0.80836728  0.1796053 ]\n",
      " [ 0.36237154 -0.1796053 ]\n",
      " [-0.52961994 -1.61644772]\n",
      " [ 0.36237154  0.89802651]\n",
      " [ 1.70035875  0.53881591]\n",
      " [-0.52961994 -0.1796053 ]\n",
      " [-0.0836242   0.89802651]\n",
      " [-0.0836242   1.25723711]\n",
      " [ 1.70035875  1.61644772]\n",
      " [ 0.36237154 -0.53881591]\n",
      " [-0.0836242   0.1796053 ]\n",
      " [ 0.80836728  0.89802651]\n",
      " [-0.97561568  0.1796053 ]\n",
      " [-0.0836242  -0.89802651]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "D:\\Programming\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "D:\\Programming\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "np.random.seed(0)\n",
    "#main\n",
    "total_remove = 4\n",
    "X, Y = prep_data('toy_dataset.csv')\n",
    "print('This is the preprocessed data')\n",
    "print(X)\n",
    "# Test ReliefF\n",
    "X_ReliefF = ReliefFSelect(X, Y, len(X)//2, 4, total_remove)\n",
    "print('This is the data chosen by the ReliefF')\n",
    "print(X_ReliefF)\n",
    "# Test linearSVM\n",
    "X_SVM = linearSVMWeightSelect(X,Y, total_remove)\n",
    "print('This is the data chosen by the Linear SVM weights')\n",
    "print(X_SVM)\n",
    "# Test combinedReliefFLinearSVM\n",
    "X_RFSVM = combinedReliefFLinearSVM(X, Y, len(X)//2, 4, 2, total_remove)\n",
    "print('This is the data chosen by the combined ReliefF and Linear SVM weights')\n",
    "print(X_RFSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on my references:\n",
    "Initial paper. Further Experiments on A Combination of Linear SVM Weight and ReliefF for Dimensionality Reduction\n",
    "(Article 3)\n",
    "\n",
    "Enhancing the Efficiency of Dimensionality ReductionUsing a Combined Linear SVM Weight with ReliefF Feature Selection Method\n",
    "9th conference book\n",
    "\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html\n",
    "Exploration of nitroimidazoles as radiosensitizers: application of multilayered feature selection approach in QSAR modeling\n",
    "ReliefF software if needed: https://libraries.io/pypi/ReliefF\n",
    "For SVM Linear Weight: https://www.csie.ntu.edu.tw/~cjlin/papers/causality.pdf\n",
    "For SVM RFE: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2451-4\n",
    "Relief-based feature selection: Introduction and review\n",
    "For ReliefF explanation: https://medium.com/@yashdagli98/feature-selection-using-relief-algorithms-with-python-example-3c2006e18f83\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
